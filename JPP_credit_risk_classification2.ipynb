{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1.0 Import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
      "0    10700.0          7.672            52800        0.431818                5   \n",
      "1     8400.0          6.692            43600        0.311927                3   \n",
      "2     9000.0          6.963            46100        0.349241                3   \n",
      "3    10700.0          7.664            52700        0.430740                5   \n",
      "4    10800.0          7.698            53000        0.433962                5   \n",
      "\n",
      "   derogatory_marks  total_debt  loan_status  \n",
      "0                 1       22800            0  \n",
      "1                 0       13600            0  \n",
      "2                 0       16100            0  \n",
      "3                 1       22700            0  \n",
      "4                 1       23000            0  \n"
     ]
    }
   ],
   "source": [
    "# 2.0 Read the CSV file from the Resources folder into a Pandas DataFrame\n",
    "df = pd.read_csv('Resources/lending_data.csv')\n",
    "\n",
    "# 2.1 Review the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 77536\n",
      "Number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "# Get the dimensions of the DataFrame\n",
    "dimensions = df.shape\n",
    "\n",
    "# Print the dimensions\n",
    "print(\"Number of rows:\", dimensions[0])\n",
    "print(\"Number of columns:\", dimensions[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labels (y): (77536,)\n",
      "Shape of features (X): (77536, 7)\n"
     ]
    }
   ],
   "source": [
    "# 3.0 Separate the data into labels and features\n",
    "# Separate the labels (y) and features (X)\n",
    "\n",
    "  # Features from the remaining columns\n",
    "\n",
    "# 3.1 Separate the y variable, the labels\n",
    "y = df['loan_status']  # Labels from the \"loan_status\" column\n",
    "\n",
    "# 3.2 Separate the X variable, the features\n",
    "X = df.drop('loan_status', axis=1)\n",
    "\n",
    "\n",
    "print(\"Shape of labels (y):\", y.shape)\n",
    "print(\"Shape of features (X):\", X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "77531    1\n",
      "77532    1\n",
      "77533    1\n",
      "77534    1\n",
      "77535    1\n",
      "Name: loan_status, Length: 77536, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4.0 Review the y variable Series\n",
    "# Review the y variable Series\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
      "0        10700.0          7.672            52800        0.431818   \n",
      "1         8400.0          6.692            43600        0.311927   \n",
      "2         9000.0          6.963            46100        0.349241   \n",
      "3        10700.0          7.664            52700        0.430740   \n",
      "4        10800.0          7.698            53000        0.433962   \n",
      "...          ...            ...              ...             ...   \n",
      "77531    19100.0         11.261            86600        0.653580   \n",
      "77532    17700.0         10.662            80900        0.629172   \n",
      "77533    17600.0         10.595            80300        0.626401   \n",
      "77534    16300.0         10.068            75300        0.601594   \n",
      "77535    15600.0          9.742            72300        0.585062   \n",
      "\n",
      "       num_of_accounts  derogatory_marks  total_debt  \n",
      "0                    5                 1       22800  \n",
      "1                    3                 0       13600  \n",
      "2                    3                 0       16100  \n",
      "3                    5                 1       22700  \n",
      "4                    5                 1       23000  \n",
      "...                ...               ...         ...  \n",
      "77531               12                 2       56600  \n",
      "77532               11                 2       50900  \n",
      "77533               11                 2       50300  \n",
      "77534               10                 2       45300  \n",
      "77535                9                 2       42300  \n",
      "\n",
      "[77536 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5.0Review the X variable DataFrame\n",
    "print(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (58152, 7)\n",
      "X_test shape: (19384, 7)\n",
      "y_train shape: (58152,)\n",
      "y_test shape: (19384,)\n"
     ]
    }
   ],
   "source": [
    "# 6.0Import the train_test_learn module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 6.1Split the data using train_test_split\n",
    "# 6.2Assign a random_state of 1 to the function\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.0Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 7.1Instantiate the Logistic Regression model\n",
    "# 7.2Assign a random_state parameter of 1 to the model\n",
    "logistic_regression_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# 7.3Fit the model using training data\n",
    "\n",
    "logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 8.0 Make a prediction using the testing data\n",
    "# Make predictions using the testing data\n",
    "testing_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Display the predictions\n",
    "print(testing_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 predictions from the NumPy array\n",
    "print(testing_predictions[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[18663   102]\n",
      " [   56   563]]\n"
     ]
    }
   ],
   "source": [
    "# 9.0 Generate a confusion matrix for the model\n",
    "conf_matrix = confusion_matrix(y_test, testing_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.85      0.91      0.88       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.95      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10.0 Print the classification report for the model\n",
    "class_report = classification_report(y_test, testing_predictions)\n",
    "print(\"\\nClassification Report:\")\n",
    "\n",
    "\n",
    "print(class_report)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:\n",
    "Based on the provided classification report and confusion matrix:\r\n",
    "\r\n",
    "For the healthy loan label (0:\r\n",
    "\r\n",
    "Precision:    .00\r\n",
    "Recall:    0.99\r\n",
    "F1-score     1.00\r\n",
    "Support     18765\r\n",
    "For the high-risk loan label (1):\r\n",
    "\r\n",
    "Preci    ion: 0.85\r\n",
    "R    call: 0.91\r\n",
    "F1    score: 0.88\r\n",
    "\n",
    "Support: 619\r\n",
    "Overall, the logistic regression model performs very well in predicting both healthy loans and high-risk loans. It has high precision and recall values for both classes, indicating that it can effectively distinguish between the two classes. The accuracy of the model is 99%, which is excellent. The model's performance is further supported by the high F1-scores for both classes.\r\n",
    "\r\n",
    "In summary, the logistic regression model demonstrates strong predictive performance for both healthy and high-risk loan labels based on the provided metrics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
